package test;

import java.io.File;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import com.huaban.analysis.jieba.JiebaSegmenter;
import com.huaban.analysis.jieba.SegToken;
import com.huaban.analysis.jieba.JiebaSegmenter.SegMode;
import com.huaban.analysis.jieba.WordDictionary;
import com.qianxinyao.analysis.jieba.keyword.Keyword;
import com.qianxinyao.analysis.jieba.keyword.TFIDFAnalyzer;

import dao.*;

public class JiebaTest {
//  java.util.HashMap<K,V>
//K - the type of keys maintained by this map
//V - the type of mapped values
//    很好了解决了该txt中一行信息，包括关键词和权重
    Map<String, Double> idfmap = new HashMap<String, Double>();
	
	public void set_idf(List<String> list){

		long startTime = System.currentTimeMillis();
		System.out.println("开始计时：");		
		long d = (System.currentTimeMillis() - startTime)/1000;
		long minute = d / 60;
		long second = d % 60;		
		System.out.println("读取数据完成，耗时：" + minute + "分" + second + "秒");
		long startTime2 = System.currentTimeMillis();

        // 生成一个Segmenter分词对象
		JiebaSegmenter segmenter = new JiebaSegmenter();
		for(int i=0;i<1000;i++){
			System.out.print(i);
			// 调用分词方法 segmenter.process(字符串,分词模式)，返回一个SegToken对象的列表
			List<SegToken> tokenList = segmenter.process(list.get(i), SegMode.SEARCH);
			for(SegToken token:tokenList){
				// 遍历列表，从列表中每个SegToken对象中，获得word。
				System.out.print("\t"+token.word);
			}
			System.out.println("");
		}


		d = (System.currentTimeMillis() - startTime2)/1000;
		minute = d / 60;
		second = d % 60;		
		System.out.println("分词1000条完成，耗时：" + minute + "分" + second + "秒");
	}
	
	public static void main(String[] args) {		
		
		
		String s = "在解决“两不愁三保障”突出问题座谈会上，他指出脱贫既要看数量，更要看质量。贫困县摘帽不摘责任、不摘政策、不摘帮扶、不摘监管；在第六个国家扶贫日到来之际，他作出重要指示，要求各地区各部门务必咬定目标、一鼓作气，坚决攻克深度贫困堡垒；在中央政治局常委会会议专门研究“三农”工作时他指出，脱贫质量怎么样、小康成色如何，很大程度上要看明年“三农”工作成效。要集中资源、强化保障、精准施策，加快补上“三农”领域短板";
		// 生成一个Segmenter分词对象
		JiebaSegmenter segmenter = new JiebaSegmenter();
		// 调用分词方法 segmenter.process(需要分词的字符串 ,分词模式)，返回的是一个SegToken对象的列表
		List<SegToken> tokenList = segmenter.process(s, SegMode.SEARCH);
		for(SegToken token:tokenList){
			// 遍历列表，从列表中每个SegToken对象中，获得word。
			System.out.println(token.word);
		}

        String content="孩子上了幼儿园 安全防拐教育要做好";
        int topN=5;
        TFIDFAnalyzer tfidfAnalyzer=new TFIDFAnalyzer();
        List<Keyword> list=tfidfAnalyzer.analyze(content,topN);
        for(Keyword word:list)
            System.out.println(word.getName()+" "+word.getTfidfvalue()+",");





	}

}
